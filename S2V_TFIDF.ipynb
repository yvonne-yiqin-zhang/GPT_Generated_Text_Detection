{"cells":[{"cell_type":"markdown","metadata":{"id":"Nph-b1jG59tw"},"source":["# TF-IDF"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PUBM--r959t1"},"outputs":[],"source":["import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"J-JiF9Eb59t3","outputId":"dae4eaa3-132f-4580-c112-780b9b35b86c"},"outputs":[{"name":"stdout","output_type":"stream","text":["train set size:  2700\n","test set size:  300\n"]}],"source":["train_set = pd.read_csv('./dataset/train_set.csv')\n","test_set = pd.read_csv('./dataset/test_set.csv')\n","\n","print('train set size: ', len(train_set))\n","print('test set size: ', len(test_set))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6__DuAql59t4"},"outputs":[],"source":["all_text = pd.concat([train_set['text'], test_set['text']], axis=0)\n","all_text = all_text.reset_index(drop=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"inRhqFDm59t5","outputId":"2686398a-4c4c-496a-ae9f-16a0c5002dbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulary size:  37155\n"]}],"source":["vectorizer = TfidfVectorizer()\n","vectorizer.fit(all_text)\n","print('vocabulary size: ', len(vectorizer.vocabulary_))\n","\n","vector_train = vectorizer.transform(train_set['text'])\n","vector_test = vectorizer.transform(test_set['text'])"]},{"cell_type":"markdown","metadata":{"id":"u6wsTNFR59t6"},"source":["Too many words, the vector is too long, we only use words with minimam frequency 10"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"0Jymab8859t7","outputId":"3212105d-ab1f-4f6d-8fdb-22af0e2e1289"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulary size:  3969\n"]}],"source":["vectorizer = TfidfVectorizer(min_df=10)\n","vectorizer.fit(all_text)\n","print('vocabulary size: ', len(vectorizer.vocabulary_))\n","\n","vector_train = vectorizer.transform(train_set['text'])\n","vector_test = vectorizer.transform(test_set['text'])"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"QzZGaCxq59t9"},"outputs":[],"source":["train_set_vector = pd.DataFrame(columns=['vector', 'label'])\n","train_set_vector['vector'] = list(vector_train.toarray())\n","train_set_vector['label'] = train_set['label']\n","\n","test_set_vector = pd.DataFrame(columns=['vector', 'label'])\n","test_set_vector['vector'] = list(vector_test.toarray())\n","test_set_vector['label'] = test_set['label']"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Fquu-D5759t-"},"outputs":[],"source":["train_set_vector.to_pickle('./dataset/train_set_vector_tfidf.pickle')\n","test_set_vector.to_pickle('./dataset/test_set_vector_tfidf.pickle')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vector</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[0.06149296993313418, 0.05370595618532828, 0.0...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[0.0, 0.0677057829077876, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[0.06098218234788164, 0.026629925476215368, 0....</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              vector  label\n","0  [0.06149296993313418, 0.05370595618532828, 0.0...      0\n","1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      1\n","2  [0.0, 0.0677057829077876, 0.0, 0.0, 0.0, 0.0, ...      1\n","3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0\n","4  [0.06098218234788164, 0.026629925476215368, 0....      0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_set_vector.head()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"NLP","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
